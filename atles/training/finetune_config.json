{
  "base_model": "Qwen/Qwen2.5-7B-Instruct",
  "output_dir": "./finetuned_models/atles_qwen2.5_7b",
  
  "lora_r": 16,
  "lora_alpha": 32,
  "lora_dropout": 0.05,
  "lora_target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj"
  ],
  
  "num_epochs": 3,
  "batch_size": 4,
  "gradient_accumulation_steps": 4,
  "learning_rate": 2e-4,
  "warmup_steps": 100,
  "max_seq_length": 2048,
  
  "train_data_path": "./training_data/atles_training_data.jsonl",
  "validation_data_path": null,
  "validation_split": 0.1,
  
  "save_steps": 500,
  "eval_steps": 500,
  "logging_steps": 100,
  "save_total_limit": 3,
  "fp16": true,
  "gradient_checkpointing": true
}

